{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5344155,"sourceType":"datasetVersion","datasetId":3102947}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{"id":"wIsb9sq_2ch4"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import norm\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score","metadata":{"id":"frte8RHuocqz","execution":{"iopub.status.busy":"2024-05-21T15:13:33.676097Z","iopub.execute_input":"2024-05-21T15:13:33.677000Z","iopub.status.idle":"2024-05-21T15:13:36.539560Z","shell.execute_reply.started":"2024-05-21T15:13:33.676915Z","shell.execute_reply":"2024-05-21T15:13:36.538493Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Function to load data","metadata":{"id":"UokvH2pq7cMt"}},{"cell_type":"code","source":"def load_data(path):\n    # Read the CSV file located at the specified 'path' into a Pandas DataFrame object\n    df = pd.read_csv(path)\n    df.shape\n\n    # Display the first few rows of the DataFrame to the console, using the head() method,\n    # to give an idea of what the data looks like before any preprocessing is done\n    print(f\"Data before Preprocessing:\\n {df.head}\")\n    return df","metadata":{"id":"ckS3DHlDdtOP","execution":{"iopub.status.busy":"2024-05-21T15:13:36.541576Z","iopub.execute_input":"2024-05-21T15:13:36.542391Z","iopub.status.idle":"2024-05-21T15:13:36.548398Z","shell.execute_reply.started":"2024-05-21T15:13:36.542356Z","shell.execute_reply":"2024-05-21T15:13:36.546920Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Function to preprocess data","metadata":{"id":"XcALLZMPdtOP"}},{"cell_type":"code","source":"def preprocess_data(df):\n    # Perform label encoding on categorical columns to convert them into numerical values\n    # that can be processed by machine learning algorithms\n    label_encoder = LabelEncoder()\n    df['gender'] = label_encoder.fit_transform(df['gender'])  # Encode gender column\n    df['smoking_history'] = label_encoder.fit_transform(df['smoking_history'])  # Encode smoking history column\n\n    # Convert the DataFrame to a NumPy array for further processing\n    data = np.array(df)\n\n    # Apply standard scaling to all columns except the last one (which is the target variable)\n    # to have similar scales and prevent features with large ranges from dominating the model\n\n    # Print the preprocessed data to the console for inspection\n    print(f\"\\nData after Preprocessing: \\n{data}\\n\")\n    return data","metadata":{"id":"j-CHJNAhdtOP","execution":{"iopub.status.busy":"2024-05-21T15:13:36.549724Z","iopub.execute_input":"2024-05-21T15:13:36.550109Z","iopub.status.idle":"2024-05-21T15:13:36.564250Z","shell.execute_reply.started":"2024-05-21T15:13:36.550079Z","shell.execute_reply":"2024-05-21T15:13:36.562852Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{"id":"zyn5hOytdtOP"}},{"cell_type":"code","source":"class FeatureExtractor():\n    def __init__(self):\n        pass\n\n    def get_min_max_scale(self, X):\n        return (X - np.min(X, axis=0)) / (np.max(X, axis=0) - np.min(X, axis=0))\n\n\n    def get_max_abs_scale(self, X):\n        # Calculate the maximum absolute value for each feature\n        max_abs = np.max(np.abs(X), axis=0)\n\n        # Scale each feature by dividing it by its maximum absolute value\n        scaled_data = X / max_abs\n\n        return scaled_data\n\n\n    def get_power_transformation(self, X, method='yeo-johnson', standardize=True):\n\n        X = np.array(X)\n\n        if standardize:\n            X_std = (X - X.mean(axis=0)) / X.std(axis=0)\n        else:\n            X_std = X\n\n        if method == 'yeo-johnson':\n            lam = np.array([(np.median(np.abs(X_std[:, i] - np.median(X_std[:, i])))) /\n                            (np.median(np.abs(X_std[:, i] + np.median(X_std[:, i])))) for i in range(X_std.shape[1])])\n            transformed_X = np.sign(X_std) * (np.abs(X_std) + lam) ** (1 / (lam + 1e-2))\n        elif method == 'box-cox':\n            lam = np.array([(np.var(X_std[:, i]) / np.mean(X_std[:, i]**2)) for i in range(X_std.shape[1])])\n            transformed_X = np.sign(X_std) * (np.abs(X_std) ** lam)\n        else:\n            raise ValueError(\"Method must be either 'yeo-johnson' or 'box-cox'\")\n\n        return transformed_X\n\n    def get_standard_scale(self, X):\n\n        # Calculate mean and standard deviation for each feature\n        mean = np.mean(X, axis=0)\n        std_dev = np.std(X, axis=0)\n\n        # Scale the data\n        scaled_data = (X - mean) / std_dev\n\n        return scaled_data\n\n    def fit_transform(self, X):\n        min_max_scaled_X = self.get_min_max_scale(X)\n        max_abs_scaled_X = self.get_max_abs_scale(X)\n        power_transformated_X = self.get_power_transformation(X)\n        standard_scaled_X = self.get_standard_scale(X)\n        merged_X = np.hstack((min_max_scaled_X, max_abs_scaled_X, power_transformated_X, standard_scaled_X))\n        return merged_X\n","metadata":{"id":"R08rQgTkdtOQ","execution":{"iopub.status.busy":"2024-05-21T15:13:36.568409Z","iopub.execute_input":"2024-05-21T15:13:36.568887Z","iopub.status.idle":"2024-05-21T15:13:36.588640Z","shell.execute_reply.started":"2024-05-21T15:13:36.568846Z","shell.execute_reply":"2024-05-21T15:13:36.586887Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# LDA class for Feature Reduction","metadata":{"id":"EDY7VN7sdtOQ"}},{"cell_type":"code","source":"class LDA:\n    def __init__(self, n_components):\n        self.n_components = n_components\n        self.linear_discriminants = None\n\n    def fit(self, X, y):\n        n_features = X.shape[1]\n        class_labels = np.unique(y)\n\n        mean_overall = np.mean(X, axis=0)\n        SW = np.zeros((n_features, n_features))\n        SB = np.zeros((n_features, n_features))\n        for c in class_labels:\n            X_c = X[y == c]\n            mean_c = np.mean(X_c, axis=0)\n            SW += (X_c - mean_c).T.dot((X_c - mean_c))\n\n            n_c = X_c.shape[0]\n            mean_diff = (mean_c - mean_overall).reshape(n_features, 1)\n            SB += n_c * (mean_diff).dot(mean_diff.T)\n\n        A = np.linalg.inv(SW).dot(SB)\n        eigenvalues, eigenvectors = np.linalg.eigh(A)\n        eigenvectors = eigenvectors.T\n        idxs = np.argsort(abs(eigenvalues))[::-1]\n        eigenvalues = eigenvalues[idxs]\n        eigenvectors = eigenvectors[idxs]\n        self.linear_discriminants = eigenvectors[0 : self.n_components]\n\n    def transform(self, X):\n        return np.dot(X, self.linear_discriminants.T)","metadata":{"id":"aDVC4nradtOQ","execution":{"iopub.status.busy":"2024-05-21T15:13:36.591353Z","iopub.execute_input":"2024-05-21T15:13:36.591728Z","iopub.status.idle":"2024-05-21T15:13:36.607503Z","shell.execute_reply.started":"2024-05-21T15:13:36.591700Z","shell.execute_reply":"2024-05-21T15:13:36.606110Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes Classifier","metadata":{"id":"RSwATjXOdtOR"}},{"cell_type":"code","source":"class GaussianNaiveBayes:\n    def __init__(self):\n        # Initialize dictionaries to store class priors, means, and variances\n        self.class_prior = {}\n        self.mean = {}\n        self.variance = {}\n\n    def fit(self, X, y):\n        # Get unique classes\n        self.classes = np.unique(y)\n\n        # Iterate over each class\n        for c in self.classes:\n            # Filter input features for the current class\n            X_c = X[y == c]\n\n            # Calculate class prior probability\n            self.class_prior[c] = len(X_c) / len(X)\n\n            # Calculate mean and variance for the current class\n            self.mean[c] = np.mean(X_c, axis=0)\n            self.variance[c] = np.var(X_c, axis=0)\n\n    def gaussian_pdf(self, x, mean, variance):\n        # Calculate the Gaussian (normal) probability density function\n        exponent = -((x - mean) ** 2) / ((2 * variance) + 10e-6) # to avoid divide by zero\n        pdf = np.exp(exponent) / (np.sqrt(2 * np.pi * variance) + 10e-6) # to avoid divide by zero\n        return pdf\n\n    def predict(self, X):\n        predictions = []\n        for x in X:\n            posteriors = []\n            for c in self.classes:\n                # Get class prior probability\n                prior = self.class_prior[c]\n\n                # Calculate likelihood using Gaussian PDF\n                likelihood = np.prod(self.gaussian_pdf(x, self.mean[c], self.variance[c]))\n\n                # Calculate posterior probability\n                posterior = prior * likelihood\n                posteriors.append(posterior)\n\n            # Get the index of the highest posterior probability class\n            predictions.append(self.classes[np.argmax(posteriors)])\n        return predictions","metadata":{"id":"F8kbvnG_dtOR","execution":{"iopub.status.busy":"2024-05-21T15:13:36.610692Z","iopub.execute_input":"2024-05-21T15:13:36.611241Z","iopub.status.idle":"2024-05-21T15:13:36.626008Z","shell.execute_reply.started":"2024-05-21T15:13:36.611197Z","shell.execute_reply":"2024-05-21T15:13:36.625064Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Function to get the accuracy","metadata":{"id":"ULcAUmlE6cbd"}},{"cell_type":"code","source":"def accuracy_rate(y, predictions):\n    # Calculate the number of correct predictions\n    # by iterating over the true labels (y) and predicted labels (predictions)\n    # and summing up the number of matches\n    correct = sum(1 for i in range(len(y)) if y[i] == predictions[i])\n\n    # Calculate the accuracy rate as a percentage\n    # by dividing the number of correct predictions by the total number of samples\n    # and multiplying by 100\n    return (correct / float(len(y))) * 100.0","metadata":{"id":"KQv3QZUedxwg","execution":{"iopub.status.busy":"2024-05-21T15:13:36.628340Z","iopub.execute_input":"2024-05-21T15:13:36.628879Z","iopub.status.idle":"2024-05-21T15:13:36.642142Z","shell.execute_reply.started":"2024-05-21T15:13:36.628845Z","shell.execute_reply":"2024-05-21T15:13:36.640825Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection (Using Grey Wolf Optimization)","metadata":{"id":"_i4z_-TPeey1"}},{"cell_type":"code","source":"def applymask(train_data,mask):\n    mask = np.where(mask > 0, True, False)\n    #Apply Mask\n    new_data = np.array(train_data[0][mask])\n    for i in range(1,len(train_data)):\n        new_data = np.vstack((new_data,train_data[i][mask]))\n\n    return new_data","metadata":{"id":"Adywq_6Cj-iW","execution":{"iopub.status.busy":"2024-05-21T15:13:36.646263Z","iopub.execute_input":"2024-05-21T15:13:36.646620Z","iopub.status.idle":"2024-05-21T15:13:36.661927Z","shell.execute_reply.started":"2024-05-21T15:13:36.646591Z","shell.execute_reply":"2024-05-21T15:13:36.660468Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# this is used to evaluate the feature / mainly it train the model and use it on subset of data\ndef fitness(train_data, validation_data, mask, score):\n    # Unpack the data tuples\n    x_train, y_train = train_data\n    x_val, y_val = validation_data\n\n    # Apply the mask (on Train Data only)\n    x_train = x_train * mask\n\n    # Create and train the SVM model\n    model = GaussianNaiveBayes()\n    model.fit(x_train, y_train)\n\n    # Make predictions on validation data\n    y_pred = model.predict(x_val)\n\n    # Calculate the desired score\n    if score == 'accuracy':\n        result = accuracy_score(y_val, y_pred)\n    elif score == 'F1':\n        result = f1_score(y_val, y_pred, average='weighted')\n    elif score == 'Precision':\n        result = precision_score(y_val, y_pred, average='weighted')\n    elif score == 'recall':\n        result = recall_score(y_val, y_pred, average='weighted')\n    else:\n        raise ValueError(\"Invalid score. Please choose from 'accuracy', 'f1', 'precision', or 'recall'.\")\n\n    return result","metadata":{"id":"QV2-paYqeiu7","execution":{"iopub.status.busy":"2024-05-21T15:13:36.664555Z","iopub.execute_input":"2024-05-21T15:13:36.665572Z","iopub.status.idle":"2024-05-21T15:13:36.674719Z","shell.execute_reply.started":"2024-05-21T15:13:36.665528Z","shell.execute_reply":"2024-05-21T15:13:36.673673Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))","metadata":{"id":"lQbFw1Geeovr","execution":{"iopub.status.busy":"2024-05-21T15:13:36.676225Z","iopub.execute_input":"2024-05-21T15:13:36.676640Z","iopub.status.idle":"2024-05-21T15:13:36.687177Z","shell.execute_reply.started":"2024-05-21T15:13:36.676607Z","shell.execute_reply":"2024-05-21T15:13:36.686065Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def CalX(top_sample,curr_sample,a): #top sample represent alpha or beta or delta wolf\n    # Define Parameter\n    features_shape = curr_sample.shape\n    A = 2*a*np.random.rand(*features_shape) - a\n    C = 2*np.random.rand(*features_shape)\n    D = abs(C*top_sample - curr_sample)\n\n    # Calculating X_\n    cstep = sigmoid(10*(A*D-0.5))\n    bstep = np.where(cstep >= np.ones(features_shape),1,0)\n    X = np.where(top_sample + bstep >= np.ones(features_shape),1,0)\n    return X","metadata":{"id":"QD9rk_3lfesH","execution":{"iopub.status.busy":"2024-05-21T15:13:36.691119Z","iopub.execute_input":"2024-05-21T15:13:36.692437Z","iopub.status.idle":"2024-05-21T15:13:36.700609Z","shell.execute_reply.started":"2024-05-21T15:13:36.692386Z","shell.execute_reply":"2024-05-21T15:13:36.699594Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def GWO_SVM(train_data,validation_data,score=\"accuracy\",population_size=10,maxiter=5):\n    # Initialize the population (wolfs), which actuallly represent masks\n    population = np.random.randint(2,size = (population_size,*train_data[0].shape[1:])) # assuming it represent feature importance to add some diversity\n    fitness_val = np.zeros(population_size)\n    features_shape = train_data[0].shape[1:]\n\n    # Calculating fitness value\n    for sample in range(population_size):\n        fitness_val[sample] = fitness(train_data,validation_data,population[sample],score)\n        delta, beta, alpha = np.argsort(fitness_val)[-3:] # alpha in last so order is delta, beta, alpha\n\n\n    for curr_iter in range(maxiter):\n        # Initialize parameters;\n        a = 2*(1 - curr_iter/maxiter) # linearly decreased from 2 to 0\n\n        for idx in range(population_size):\n            # Calculating for X1,X2 and X3\n            X1 = CalX(alpha,population[idx],a)\n            X2 = CalX(beta,population[idx],a)\n            X3 = CalX(delta,population[idx],a)\n\n            # Greedy Selection\n            new_point = sigmoid(np.mean((X1,X2,X3),axis=0)) #sigmoid function\n            new_point = np.where(new_point>np.random.rand(*features_shape),1,0) #make it discrete\n            new_fit = fitness(train_data,validation_data,new_point,score)\n\n            # Update if Better\n            if new_fit >= fitness_val[idx]:\n                fitness_val[idx] = new_fit\n                population[idx] = new_point\n\n\n            # Recalculate new delta, beta, alpha\n            delta, beta, alpha = np.argsort(fitness_val)[-3:]\n\n\n    return population[alpha]","metadata":{"id":"EZ8ajHvIfguT","execution":{"iopub.status.busy":"2024-05-21T15:13:36.702367Z","iopub.execute_input":"2024-05-21T15:13:36.702885Z","iopub.status.idle":"2024-05-21T15:13:36.722208Z","shell.execute_reply.started":"2024-05-21T15:13:36.702841Z","shell.execute_reply":"2024-05-21T15:13:36.721036Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def select_features(X,y):\n    # split the data to validation and train data\n    x_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n    res = GWO_SVM((x_train, y_train), (x_valid, y_valid),population_size=10,maxiter=5)\n\n    #Apply Mask\n    res = np.where(res > 0, True, False)\n    print(f\"From {len(res)}. The GWO selected Only {np.count_nonzero(res)} Features\")\n\n    new_data = np.array(X[0][res])\n    for i in range(1,len(X)):\n        new_data = np.vstack((new_data,X[i][res]))\n    print(f\"Shape of data after Feature Selection: {new_data.shape}\\n\")\n\n    return new_data","metadata":{"id":"EVPkA5PofjXK","execution":{"iopub.status.busy":"2024-05-21T15:13:36.723970Z","iopub.execute_input":"2024-05-21T15:13:36.724612Z","iopub.status.idle":"2024-05-21T15:13:36.739579Z","shell.execute_reply.started":"2024-05-21T15:13:36.724580Z","shell.execute_reply":"2024-05-21T15:13:36.738137Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Function to run the whole program","metadata":{"id":"17broCZO-g3p"}},{"cell_type":"code","source":"def run():\n    # Load the diabetes prediction dataset from a CSV file\n    df = load_data(\"/kaggle/input/diabetes-prediction-dataset/diabetes_prediction_dataset.csv\")\n\n    # Print the number of features in the data (excluding the target variable)\n    print(f\"\\nNo. features in data: {df.iloc[:,:-1].shape[1]}\\n\")\n\n    # Preprocess the data (e.g., label encoding, standard scaling)\n    data = preprocess_data(df)\n    X=data[:,:-1]\n    y=data[:,-1]\n\n    fe = FeatureExtractor()\n    extracted_features = fe.fit_transform(X)\n    print(f\"No. Extractd features: {extracted_features.shape[1]}\\n\")\n\n    lda = LDA(20)\n    lda.fit(extracted_features, y)\n    X_projected = lda.transform(extracted_features)\n    \n    print(f\"Shape of data after Feature Reduction: {X_projected.shape}\\n\")\n\n    # paper name: https://www.hindawi.com/journals/cmmm/2017/9512741/\n\n    X_projected = select_features(X_projected,y)\n\n    # Split the preprocessed data into training and testing sets (80% for training, 20% for testing)\n    X_train, X_test, y_train, y_test = train_test_split(X_projected, y, test_size=0.2, random_state=42)\n\n    # Create an instance of the Naive Bayes classifier\n    nb = GaussianNaiveBayes()\n\n    # Train the Naive Bayes model on the training data\n    nb.fit(X_train, y_train)\n\n    # Use the trained model to make predictions on the testing data\n    y_pred = nb.predict(X_test)\n\n    # Evaluate the accuracy of the model by comparing the predicted labels with the true labels\n    print(\"Accuracy: \", accuracy_rate(y_test, y_pred))","metadata":{"id":"MFGCuoOD-Bkx","execution":{"iopub.status.busy":"2024-05-21T15:13:36.740875Z","iopub.execute_input":"2024-05-21T15:13:36.741280Z","iopub.status.idle":"2024-05-21T15:13:36.758576Z","shell.execute_reply.started":"2024-05-21T15:13:36.741247Z","shell.execute_reply":"2024-05-21T15:13:36.757234Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Run With Feature Selection","metadata":{"id":"LYC23ephh0Or"}},{"cell_type":"code","source":"run()","metadata":{"id":"ZAsCojkchUXG","outputId":"577f29e1-83a5-4c84-e132-5d6cfc04ac3c","execution":{"iopub.status.busy":"2024-05-21T15:13:41.392613Z","iopub.execute_input":"2024-05-21T15:13:41.393010Z","iopub.status.idle":"2024-05-21T15:16:34.374525Z","shell.execute_reply.started":"2024-05-21T15:13:41.392980Z","shell.execute_reply":"2024-05-21T15:16:34.373204Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Data before Preprocessing:\n <bound method NDFrame.head of        gender   age  hypertension  heart_disease smoking_history    bmi  \\\n0      Female  80.0             0              1           never  25.19   \n1      Female  54.0             0              0         No Info  27.32   \n2        Male  28.0             0              0           never  27.32   \n3      Female  36.0             0              0         current  23.45   \n4        Male  76.0             1              1         current  20.14   \n...       ...   ...           ...            ...             ...    ...   \n99995  Female  80.0             0              0         No Info  27.32   \n99996  Female   2.0             0              0         No Info  17.37   \n99997    Male  66.0             0              0          former  27.83   \n99998  Female  24.0             0              0           never  35.42   \n99999  Female  57.0             0              0         current  22.43   \n\n       HbA1c_level  blood_glucose_level  diabetes  \n0              6.6                  140         0  \n1              6.6                   80         0  \n2              5.7                  158         0  \n3              5.0                  155         0  \n4              4.8                  155         0  \n...            ...                  ...       ...  \n99995          6.2                   90         0  \n99996          6.5                  100         0  \n99997          5.7                  155         0  \n99998          4.0                  100         0  \n99999          6.6                   90         0  \n\n[100000 rows x 9 columns]>\n\nNo. features in data: 8\n\n\nData after Preprocessing: \n[[  0.   80.    0.  ...   6.6 140.    0. ]\n [  0.   54.    0.  ...   6.6  80.    0. ]\n [  1.   28.    0.  ...   5.7 158.    0. ]\n ...\n [  1.   66.    0.  ...   5.7 155.    0. ]\n [  0.   24.    0.  ...   4.  100.    0. ]\n [  0.   57.    0.  ...   6.6  90.    0. ]]\n\nNo. Extractd features: 32\n\nShape of data after Feature Reduction: (100000, 20)\n\nFrom 20. The GWO selected Only 13 Features\nShape of data after Feature Selection: (100000, 13)\n\nAccuracy:  91.46\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}